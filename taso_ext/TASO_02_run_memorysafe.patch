Index: include/taso/ops.h
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- include/taso/ops.h	(revision 9ea6c78a6e1584c441c9c205c3b3f73592ff0d51)
+++ include/taso/ops.h	(revision 2589ce88b052373161fbcdfe8adc9bc09454974b)
@@ -660,6 +660,7 @@
   bool has_loop(void);
   float total_cost(void);
   float run();
+  float run_memorysafe();
   void print_costs(void);
   void print_measurements(void);
 #ifdef TRT
Index: python/taso/_cython/CCore.pxd
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- python/taso/_cython/CCore.pxd	(revision 9ea6c78a6e1584c441c9c205c3b3f73592ff0d51)
+++ python/taso/_cython/CCore.pxd	(revision 2589ce88b052373161fbcdfe8adc9bc09454974b)
@@ -270,3 +270,4 @@
         void print_measurements()
         float total_cost()
         float run()
+        float run_memorysafe()
Index: python/taso/_cython/core.pyx
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- python/taso/_cython/core.pyx	(revision 9ea6c78a6e1584c441c9c205c3b3f73592ff0d51)
+++ python/taso/_cython/core.pyx	(revision 2589ce88b052373161fbcdfe8adc9bc09454974b)
@@ -175,6 +175,9 @@
     def run_time(self):
         return self.p_graph.run()

+    def run_time_memorysafe(self):
+        return self.p_graph.run_memorysafe()
+
     def cost(self):
         return self.p_graph.total_cost()

Index: src/core/ops.cc
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- src/core/ops.cc	(revision 9ea6c78a6e1584c441c9c205c3b3f73592ff0d51)
+++ src/core/ops.cc	(revision 2589ce88b052373161fbcdfe8adc9bc09454974b)
@@ -1362,6 +1362,258 @@
   return model->measure_oplist_runtime(opBaseList);
 }

+
+float Graph::run_memorysafe(void)
+{
+    std::map<Op, int, OpCompare> todos;
+    std::map<Op, std::set<Edge, EdgeCompare>, OpCompare>::const_iterator it;
+    std::vector<Op> opList;
+    std::vector<OpBase*> opBaseList;
+    for (it = inEdges.begin(); it != inEdges.end(); it++) {
+        int cnt = 0;
+        std::set<Edge, EdgeCompare> inList = it->second;
+        std::set<Edge, EdgeCompare>::const_iterator it2;
+        for (it2 = inList.begin(); it2 != inList.end(); it2++) {
+            if (it2->srcOp.guid > GUID_PRESERVED) cnt ++;
+        }
+        todos[it->first] = cnt;
+        if (todos[it->first] == 0)
+            opList.push_back(it->first);
+    }
+    size_t i = 0;
+    while (i < opList.size()) {
+        Op op = opList[i++];
+        std::set<Edge, EdgeCompare> outList = outEdges[op];
+        std::set<Edge, EdgeCompare> inList = inEdges[op];
+        std::set<Edge, EdgeCompare>::const_iterator it2;
+        assert(inList.size() > 0);
+        OpBase* opPtr = NULL;
+        // Step 1: prepare inputs
+        Tensor inputs[MAX_NUM_INPUTS];
+        if ((op.ptr->type == OP_INPUT) || (op.ptr->type == OP_WEIGHT)) {
+            assert(inList.size() == 1);
+            //Edge e = *inList.begin();
+            //assert(e.srcOp.ptr == NULL); // NoOp's input must not be any Op
+            Tensor t = op.ptr->inputs[0];
+            size_t size = sizeof(DATATYPE);
+            for (int j = 0; j < t.numDim; j++)
+                size *= t.dim[j];
+            if (op.ptr->type == OP_INPUT) {
+                assert(t.data_ptr == NULL);
+                t.data_ptr = (DATATYPE*) model->allocate_memory(size);
+            } else {
+                assert(t.data_ptr != NULL);
+            }
+            inputs[0] = t;
+        } else {
+            for (it2 = inList.begin(); it2 != inList.end(); it2++) {
+                size_t idx2 = 0;
+                for (idx2 = 0; idx2 < opList.size(); idx2++) {
+                    if (opList[idx2].guid == it2->srcOp.guid) break;
+                }
+                assert(idx2 < i);
+                assert(inputs[it2->dstIdx].data_ptr == NULL); // No duplicated dstIdxes
+                inputs[it2->dstIdx] = opBaseList[idx2]->outputs[it2->srcIdx];
+            }
+        }
+#ifdef DEADCODE
+        // Step 1: prepare inputs
+    for (it2 = inList.begin(); it2 != inList.end(); it2++) {
+      Edge e = *it2;
+      if (e.srcOp.guid == GUID_INPUT) {
+        Tensor t = op.ptr->inputs[e.dstIdx];
+        t.ptr = (DATATYPE*) model->allocate_memory(sizeof(DATATYPE) * t.size());
+        assert(inputs[e.dstIdx].ptr == NULL); // No duplicated dstIdxes
+        inputs[e.dstIdx] = t;
+      } else if (e.srcOp.guid = GUID_WEIGHT) {
+        Tensor t = op.ptr->inputs[e.dstIdx];
+        t.ptr = (DATATYPE*) model->allocate_memory(sizeof(DATATYPE) * t.size());
+        assert(inputs[e.dstIdx].ptr == NULL); // No duplicated dstIdxes
+        inputs[e.dstIdx] = t;
+      } else {
+        size_t idx2 = 0;
+        for (idx2 = 0; idx2 < opList.size(); idx2++) {
+          if (opList[idx2].guid == e.srcOp.guid) break;
+        }
+        assert(idx2 < i);
+        assert(inputs[e.dstIdx].ptr == NULL); // No duplicated dstIdxes
+        inputs[e.dstIdx] = opBaseList[idx2]->outputs[it2->srcIdx];
+      }
+    }
+#endif
+        // Step 2: create Ops
+        switch (op.ptr->type) {
+            case OP_CONV2D:
+            {
+                Conv2D* conv = (Conv2D*) op.ptr;
+                assert(inList.size() == 2);
+                opPtr = new Conv2D(model, inputs[0], inputs[1],
+                                   conv->strideH, conv->strideW,
+                                   conv->padding, conv->activation);
+#ifdef USE_CUDNN
+                ((Conv2D*)opPtr)->fwdAlgo = conv->fwdAlgo;
+#endif
+                break;
+            }
+            case OP_MATMUL:
+            {
+                Matmul* matmul = (Matmul*) op.ptr;
+                assert(inList.size() == 2);
+                opPtr = new Matmul(model, inputs[0], inputs[1], matmul->activation);
+                break;
+            }
+            case OP_RESHAPE:
+            {
+                Reshape* reshape = (Reshape*) op.ptr;
+                assert(inList.size() == 1);
+                std::vector<int> shape;
+                for (int i = 0; i < reshape->outputs[0].numDim; i++)
+                    shape.push_back(reshape->outputs[0].dim[i]);
+                opPtr = new Reshape(model, inputs[0], shape);
+                break;
+            }
+            case OP_TRANSPOSE:
+            {
+                Transpose* transpose = (Transpose*) op.ptr;
+                assert(inList.size() == 1);
+                int ndim = inputs[0].numDim, permIdx = transpose->permIdx;
+                std::vector<int> permVec;
+                int permArray[MAX_DIM];
+                for (int i = ndim - 1; i >= 0; i--) {
+                    permArray[i] = permIdx % ndim;
+                    permIdx = permIdx / ndim;
+                }
+                assert(permIdx == 0);
+                for (int i = 0; i < ndim; i++)
+                    for (int j = i + 1; j < ndim; j++)
+                        assert(permArray[i] != permArray[j]);
+                for (int i = 0; i < ndim; i++)
+                    permVec.push_back(permArray[i]);
+                opPtr = new Transpose(model, inputs[0], permVec, transpose->shuffle);
+                break;
+            }
+            case OP_EW_ADD:
+            case OP_EW_MUL:
+            {
+                //Element* element = (Element*) op.ptr;
+                assert(inList.size() == 2);
+                opPtr = new Element(model, op.ptr->type, inputs[0], inputs[1]);
+                break;
+            }
+            case OP_ENLARGE:
+            {
+                //Enlarge* enlarge = (Enlarge*) op.ptr;
+                assert(inList.size() == 2);
+                opPtr = new Enlarge(model, inputs[0], inputs[1]);
+                break;
+            }
+            case OP_MERGE_GCONV:
+            {
+                MergeGConv* merge = (MergeGConv*) op.ptr;
+                assert(inList.size() == 1);
+                opPtr = new MergeGConv(model, inputs[0], merge->count);
+                break;
+            }
+            case OP_POOL2D_MAX:
+            case OP_POOL2D_AVG:
+            {
+                Pool2D* pool = (Pool2D*) op.ptr;
+                assert(inList.size() == 2);
+                opPtr = new Pool2D(model, inputs[0], inputs[1], pool->type,
+                                   pool->kernelH, pool->kernelW,
+                                   pool->strideH, pool->strideW,
+                                   pool->padding, pool->activation);
+                break;
+            }
+            case OP_RELU:
+            case OP_SIGMOID:
+            case OP_TANH:
+            {
+                Activation* act = (Activation*) op.ptr;
+                assert(inList.size() == 1);
+                opPtr = new Activation(model, inputs[0], act->type, act->inPlace);
+                break;
+            }
+            case OP_BATCHNORM:
+            {
+                assert(inList.size() == 5);
+		 // TODO (gh512): original file does not compile because the epislon is not provided
+		 // to the BatchNorm, as the last argument
+   		 // opPtr = new BatchNorm(model, inputs[0], inputs[1], inputs[2], inputs[3], inputs[4]);
+ 	 	 // a quick fix here is to add a fixed constant 0.001 temporaril
+                opPtr = new BatchNorm(model, inputs[0], inputs[1], inputs[2], inputs[3], inputs[4], 0.001);
+                break;
+            }
+            case OP_SPLIT:
+            {
+                Split* split = (Split*) op.ptr;
+                assert(inList.size() == 1);
+                opPtr = new Split(model, inputs[0], split->axis, split->sizes);
+                break;
+            }
+            case OP_INPUT:
+            case OP_WEIGHT:
+            case OP_DROPOUT:
+            {
+                assert(inList.size() == 1);
+                opPtr = new NoOp(model, inputs[0], op.ptr->type);
+                break;
+            }
+            case OP_CONCAT:
+            {
+                Concat* concat = (Concat*) op.ptr;
+                opPtr = new Concat(model, concat->axis, inList.size(), inputs, concat->needCopy);
+                break;
+            }
+            default:
+                printf("op.type = %d\n", op.ptr->type);
+                assert(false);
+        }
+        // Step 3: map new Op
+        opPtr->map();
+        opBaseList.push_back(opPtr);
+        for (it2 = outList.begin(); it2 != outList.end(); it2++) {
+            todos[it2->dstOp] --;
+            //printf("myOp(%zu) dstOp(%zu) dstType(%d) dstTodos(%d)\n",
+            //    it2->srcOp.guid, it2->dstOp.guid,
+            //    it2->dstOp.ptr->type, todos[it2->dstOp]);
+            if (todos[it2->dstOp] == 0) {
+                opList.push_back(it2->dstOp);
+            }
+        }
+    }
+#ifdef VERBOSE_PRINTS
+    for (size_t i =0; i < opList.size(); i++) {
+    printf("opList[%d]: guid(%zu) type(%d)\n", i, opList[i].guid,
+           opList[i].ptr->type);
+  }
+  for (it = inEdges.begin(); it != inEdges.end(); it++) {
+    printf("op: guid(%zu) type(%d)\n", it->first.guid, it->first.ptr->type);
+    std::set<Edge, EdgeCompare> inList = it->second;
+    std::set<Edge, EdgeCompare>::const_iterator it2;
+    int cnt = 0;
+    for (it2 = inList.begin(); it2 != inList.end(); it2++) {
+      printf("    inEdge[%d]: srcOp(%zu) srcIdx(%d) dstOp(%zu) dstIdx(%d)\n", cnt++, it2->srcOp.guid, it2->srcIdx, it2->dstOp.guid, it2->dstIdx);
+    }
+  }
+#endif
+
+    assert(opList.size() == inEdges.size());
+    assert(opList.size() == opBaseList.size());
+
+    float result = model->measure_oplist_runtime(opBaseList);
+
+    // Now free GPU memory from the opList
+    for (int i = 0; i < opBaseList.size(); i++) {
+      OpBase* opBase = opBaseList[i];
+      opBase->unmap();
+      free(opBase);
+      opBase = nullptr;
+    }
+
+    return result;
+}
+
 void Graph::print_costs(void)
 {
   float exe_time = 0, flops = 0, mem_acc = 0;
